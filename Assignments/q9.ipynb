{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8af114c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T16:47:16.039408Z",
     "iopub.status.busy": "2025-07-18T16:47:16.039149Z",
     "iopub.status.idle": "2025-07-18T16:47:26.626989Z",
     "shell.execute_reply": "2025-07-18T16:47:26.626328Z"
    },
    "papermill": {
     "duration": 10.59233,
     "end_time": "2025-07-18T16:47:26.628346",
     "exception": false,
     "start_time": "2025-07-18T16:47:16.036016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- 1. IMPORTS AND SETUP ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Subset, Dataset, ConcatDataset\n",
    "from torchvision.utils import save_image\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "355e9969",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T16:47:26.633253Z",
     "iopub.status.busy": "2025-07-18T16:47:26.632945Z",
     "iopub.status.idle": "2025-07-18T16:47:26.697920Z",
     "shell.execute_reply": "2025-07-18T16:47:26.697141Z"
    },
    "papermill": {
     "duration": 0.068417,
     "end_time": "2025-07-18T16:47:26.699042",
     "exception": false,
     "start_time": "2025-07-18T16:47:26.630625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded. Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "class Config_Q9:\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    num_workers = 2\n",
    "    dataset_path = '/kaggle/input/dgm-animals/Animals_data/animals/animals'\n",
    "    q6_output_dir = '/kaggle/input/dgm_q6_results/pytorch/default/1/Q6_cGAN_20_classes_G_heavy'\n",
    "    q8_output_dir = '/kaggle/input/dgm_q8_results/pytorch/default/1/Q8_ResNet_20_classes'\n",
    "    aug_data_dir = '/kaggle/working/Q9_augmented_data'\n",
    "    num_images_per_class_to_gen = 100\n",
    "    num_classes = 20\n",
    "    batch_size = 32\n",
    "    num_epochs = 20\n",
    "    lr = 0.001\n",
    "    output_dir = '/kaggle/working/Q9_ResNet_augmented'\n",
    "\n",
    "config = Config_Q9()\n",
    "os.makedirs(config.output_dir, exist_ok=True)\n",
    "os.makedirs(config.aug_data_dir, exist_ok=True)\n",
    "print(f\"Configuration loaded. Using device: {config.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04aa320f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T16:47:26.703702Z",
     "iopub.status.busy": "2025-07-18T16:47:26.703266Z",
     "iopub.status.idle": "2025-07-18T16:47:26.710271Z",
     "shell.execute_reply": "2025-07-18T16:47:26.709578Z"
    },
    "papermill": {
     "duration": 0.010396,
     "end_time": "2025-07-18T16:47:26.711383",
     "exception": false,
     "start_time": "2025-07-18T16:47:26.700987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConditionalGenerator(nn.Module):\n",
    "    def __init__(self, latent_dim, num_classes, embedding_dim, channels_img, features_g):\n",
    "        super(ConditionalGenerator, self).__init__(); self.embed = nn.Embedding(num_classes, embedding_dim)\n",
    "        self.net = nn.Sequential(\n",
    "            self._block(latent_dim+embedding_dim, features_g*16, 4, 1, 0), self._block(features_g*16, features_g*8, 4, 2, 1),\n",
    "            self._block(features_g*8, features_g*4, 4, 2, 1), self._block(features_g*4, features_g*2, 4, 2, 1),\n",
    "            self._block(features_g*2, features_g, 4, 2, 1), nn.ConvTranspose2d(features_g, channels_img, 4, 2, 1), nn.Tanh())\n",
    "    def _block(self, i, o, k, s, p): return nn.Sequential(nn.ConvTranspose2d(i, o, k, s, p, bias=False), nn.BatchNorm2d(o), nn.ReLU(True))\n",
    "    def forward(self, z, l): return self.net(torch.cat([z, self.embed(l).unsqueeze(2).unsqueeze(3)], 1))\n",
    "\n",
    "class ClassSubsetDataset(Dataset):\n",
    "    def __init__(self, subset, class_mapping): self.subset, self.class_mapping = subset, class_mapping\n",
    "    def __getitem__(self, i): img, orig_l = self.subset[i]; new_l = self.class_mapping[orig_l]; return img, new_l\n",
    "    def __len__(self): return len(self.subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8403ea1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T16:47:26.715562Z",
     "iopub.status.busy": "2025-07-18T16:47:26.715341Z",
     "iopub.status.idle": "2025-07-18T16:47:38.995661Z",
     "shell.execute_reply": "2025-07-18T16:47:38.993866Z"
    },
    "papermill": {
     "duration": 12.284123,
     "end_time": "2025-07-18T16:47:38.997259",
     "exception": false,
     "start_time": "2025-07-18T16:47:26.713136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded c-GAN from Question 6.\n",
      "Generating 100 images for each of the 20 classes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Classes: 100%|██████████| 20/20 [00:11<00:00,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented data generation complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- GENERATE AUGMENTED DATA ---\n",
    "gen_q6 = ConditionalGenerator(100, config.num_classes, 100, 3, 64).to(config.device)\n",
    "gen_q6.load_state_dict(torch.load(os.path.join(config.q6_output_dir, 'generator_20_class.pth')))\n",
    "gen_q6.eval()\n",
    "print(\"Loaded c-GAN from Question 6.\")\n",
    "\n",
    "selected_class_names = np.load(os.path.join(config.q6_output_dir, 'selected_class_names.npy'))\n",
    "\n",
    "print(f\"Generating {config.num_images_per_class_to_gen} images for each of the {len(selected_class_names)} classes...\")\n",
    "for i, class_name in enumerate(tqdm(selected_class_names, desc=\"Generating Classes\")):\n",
    "    class_dir = os.path.join(config.aug_data_dir, class_name)\n",
    "    os.makedirs(class_dir, exist_ok=True)\n",
    "    with torch.no_grad():\n",
    "        noise = torch.randn(config.num_images_per_class_to_gen, 100, 1, 1, device=config.device)\n",
    "        labels = torch.full((config.num_images_per_class_to_gen,), i, device=config.device, dtype=torch.long)\n",
    "        fake_images = gen_q6(noise, labels).detach().cpu()\n",
    "        for j, image in enumerate(fake_images):\n",
    "            save_image(image, os.path.join(class_dir, f\"fake_{j+1}.png\"), normalize=True)\n",
    "print(\"Augmented data generation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a324307b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T16:47:39.005821Z",
     "iopub.status.busy": "2025-07-18T16:47:39.005459Z",
     "iopub.status.idle": "2025-07-18T16:53:32.136246Z",
     "shell.execute_reply": "2025-07-18T16:53:32.135242Z"
    },
    "papermill": {
     "duration": 353.136857,
     "end_time": "2025-07-18T16:53:32.137772",
     "exception": false,
     "start_time": "2025-07-18T16:47:39.000915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented training dataset created with 3193 total images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 188MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting retraining on augmented data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 100/100 [00:18<00:00,  5.54it/s]\n",
      "Epoch 2/20: 100%|██████████| 100/100 [00:17<00:00,  5.84it/s]\n",
      "Epoch 3/20: 100%|██████████| 100/100 [00:17<00:00,  5.81it/s]\n",
      "Epoch 4/20: 100%|██████████| 100/100 [00:17<00:00,  5.77it/s]\n",
      "Epoch 5/20: 100%|██████████| 100/100 [00:17<00:00,  5.82it/s]\n",
      "Epoch 6/20: 100%|██████████| 100/100 [00:17<00:00,  5.82it/s]\n",
      "Epoch 7/20: 100%|██████████| 100/100 [00:17<00:00,  5.79it/s]\n",
      "Epoch 8/20: 100%|██████████| 100/100 [00:17<00:00,  5.80it/s]\n",
      "Epoch 9/20: 100%|██████████| 100/100 [00:17<00:00,  5.80it/s]\n",
      "Epoch 10/20: 100%|██████████| 100/100 [00:17<00:00,  5.83it/s]\n",
      "Epoch 11/20: 100%|██████████| 100/100 [00:17<00:00,  5.83it/s]\n",
      "Epoch 12/20: 100%|██████████| 100/100 [00:17<00:00,  5.75it/s]\n",
      "Epoch 13/20: 100%|██████████| 100/100 [00:17<00:00,  5.80it/s]\n",
      "Epoch 14/20: 100%|██████████| 100/100 [00:17<00:00,  5.82it/s]\n",
      "Epoch 15/20: 100%|██████████| 100/100 [00:17<00:00,  5.83it/s]\n",
      "Epoch 16/20: 100%|██████████| 100/100 [00:17<00:00,  5.83it/s]\n",
      "Epoch 17/20: 100%|██████████| 100/100 [00:17<00:00,  5.83it/s]\n",
      "Epoch 18/20: 100%|██████████| 100/100 [00:17<00:00,  5.81it/s]\n",
      "Epoch 19/20: 100%|██████████| 100/100 [00:17<00:00,  5.80it/s]\n",
      "Epoch 20/20: 100%|██████████| 100/100 [00:17<00:00,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- CREATE AUGMENTED DATASET AND RETRAIN CLASSIFIER ---\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224), transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256), transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "}\n",
    "\n",
    "# Create the original real dataset for the 20 classes\n",
    "full_dataset = datasets.ImageFolder(root=config.dataset_path, transform=data_transforms['train'])\n",
    "class_mapping = torch.load(os.path.join(config.q6_output_dir, 'class_mapping.pth'))\n",
    "selected_class_indices = [full_dataset.class_to_idx[name] for name in selected_class_names]\n",
    "subset_indices = [i for i, (_, label_idx) in enumerate(full_dataset.samples) if label_idx in selected_class_indices]\n",
    "real_train_dataset = ClassSubsetDataset(Subset(full_dataset, subset_indices), class_mapping)\n",
    "\n",
    "# Create the fake dataset from the generated images\n",
    "fake_dataset = datasets.ImageFolder(root=config.aug_data_dir, transform=data_transforms['train'])\n",
    "fake_dataset.class_to_idx = {class_name: i for i, class_name in enumerate(selected_class_names)}\n",
    "\n",
    "# Combine them\n",
    "augmented_train_dataset = ConcatDataset([real_train_dataset, fake_dataset])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader_aug = DataLoader(augmented_train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=config.num_workers)\n",
    "full_dataset_val = datasets.ImageFolder(root=config.dataset_path, transform=data_transforms['val'])\n",
    "val_dataset_real = ClassSubsetDataset(Subset(full_dataset_val, subset_indices), class_mapping)\n",
    "val_loader = DataLoader(val_dataset_real, batch_size=config.batch_size, shuffle=False, num_workers=config.num_workers)\n",
    "print(f\"Augmented training dataset created with {len(augmented_train_dataset)} total images.\")\n",
    "\n",
    "# Retrain the model on augmented data\n",
    "model_q9 = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "model_q9.fc = nn.Linear(model_q9.fc.in_features, config.num_classes)\n",
    "model_q9 = model_q9.to(config.device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_aug = optim.Adam(model_q9.parameters(), lr=config.lr)\n",
    "print(\"\\nStarting retraining on augmented data...\")\n",
    "\n",
    "for epoch in range(config.num_epochs):\n",
    "    model_q9.train()\n",
    "    for inputs, labels in tqdm(train_loader_aug, desc=f\"Epoch {epoch+1}/{config.num_epochs}\"):\n",
    "        inputs, labels = inputs.to(config.device), labels.to(config.device)\n",
    "        optimizer_aug.zero_grad(); outputs = model_q9(inputs); loss = criterion(outputs, labels)\n",
    "        loss.backward(); optimizer_aug.step()\n",
    "print(\"Retraining finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d95d6f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T16:53:32.299135Z",
     "iopub.status.busy": "2025-07-18T16:53:32.298850Z",
     "iopub.status.idle": "2025-07-18T16:53:50.211649Z",
     "shell.execute_reply": "2025-07-18T16:53:50.210617Z"
    },
    "papermill": {
     "duration": 17.994611,
     "end_time": "2025-07-18T16:53:50.213031",
     "exception": false,
     "start_time": "2025-07-18T16:53:32.218420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################################\n",
      "              Question 9: Final Comparison\n",
      "##################################################\n",
      "\n",
      "Classifier WITHOUT Augmentation (Q8):\n",
      "  - Accuracy: 0.9941\n",
      "  - F1 Score: 0.9941\n",
      "\n",
      "Classifier WITH GAN Augmentation (Q9):\n",
      "  - Accuracy: 0.9413\n",
      "  - F1 Score: 0.9400\n",
      "\n",
      "--------------------------------------------------\n",
      "Difference (Augmented - Original):\n",
      "  - Accuracy Delta: -0.0528\n",
      "  - F1 Score Delta: -0.0542\n",
      "##################################################\n"
     ]
    }
   ],
   "source": [
    "# --- FINAL COMPARISON ---\n",
    "model_q9.eval()\n",
    "all_preds_q9, all_labels_q9 = [], []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        outputs = model_q9(inputs.to(config.device)); _, preds = torch.max(outputs, 1)\n",
    "        all_preds_q9.extend(preds.cpu().numpy()); all_labels_q9.extend(labels.cpu().numpy())\n",
    "final_accuracy_q9 = accuracy_score(all_labels_q9, all_preds_q9)\n",
    "final_f1_score_q9 = f1_score(all_labels_q9, all_preds_q9, average='weighted')\n",
    "\n",
    "# Evaluate the old Q8 model for comparison\n",
    "model_q8 = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "model_q8.fc = nn.Linear(model_q8.fc.in_features, config.num_classes)\n",
    "model_q8.load_state_dict(torch.load(os.path.join(config.q8_output_dir, 'best_model_q8.pth')))\n",
    "model_q8 = model_q8.to(config.device)\n",
    "model_q8.eval()\n",
    "all_preds_q8, all_labels_q8 = [], []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        outputs = model_q8(inputs.to(config.device)); _, preds = torch.max(outputs, 1)\n",
    "        all_preds_q8.extend(preds.cpu().numpy()); all_labels_q8.extend(labels.cpu().numpy())\n",
    "final_accuracy_q8 = accuracy_score(all_labels_q8, all_preds_q8)\n",
    "final_f1_score_q8 = f1_score(all_labels_q8, all_preds_q8, average='weighted')\n",
    "\n",
    "# Print the final comparison report\n",
    "print(\"\\n\" + \"#\"*50)\n",
    "print(\"              Question 9: Final Comparison\")\n",
    "print(\"#\"*50)\n",
    "print(f\"\\nClassifier WITHOUT Augmentation (Q8):\")\n",
    "print(f\"  - Accuracy: {final_accuracy_q8:.4f}\")\n",
    "print(f\"  - F1 Score: {final_f1_score_q8:.4f}\")\n",
    "print(f\"\\nClassifier WITH GAN Augmentation (Q9):\")\n",
    "print(f\"  - Accuracy: {final_accuracy_q9:.4f}\")\n",
    "print(f\"  - F1 Score: {final_f1_score_q9:.4f}\")\n",
    "acc_diff = final_accuracy_q9 - final_accuracy_q8\n",
    "f1_diff = final_f1_score_q9 - final_f1_score_q8\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "print(\"Difference (Augmented - Original):\")\n",
    "print(f\"  - Accuracy Delta: {acc_diff:+.4f}\")\n",
    "print(f\"  - F1 Score Delta: {f1_diff:+.4f}\")\n",
    "print(\"#\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137085c0",
   "metadata": {
    "papermill": {
     "duration": 0.079485,
     "end_time": "2025-07-18T16:53:50.373614",
     "exception": false,
     "start_time": "2025-07-18T16:53:50.294129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd59502",
   "metadata": {
    "papermill": {
     "duration": 0.079085,
     "end_time": "2025-07-18T16:53:50.532981",
     "exception": false,
     "start_time": "2025-07-18T16:53:50.453896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7888962,
     "sourceId": 12499911,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 403342,
     "modelInstanceId": 383933,
     "sourceId": 477395,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 403353,
     "modelInstanceId": 383944,
     "sourceId": 477408,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 401.411484,
   "end_time": "2025-07-18T16:53:53.332938",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-18T16:47:11.921454",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
